{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "\n",
    "def calculating_age(loan_id, id_card):\n",
    "    try:\n",
    "        data_in = parse(re.findall(r'\\d{8}', loan_id)[0])\n",
    "    except IndexError:\n",
    "        data_in = datetime.today()\n",
    "    born = parse(id_card[6:14])\n",
    "    try:\n",
    "        birthday = born.replace(year=data_in.year)\n",
    "    except ValueError:\n",
    "        birthday = born.replace(year=data_in.year, day=28)\n",
    "    if birthday > born:\n",
    "        return data_in.year - born.year - 1\n",
    "    else:\n",
    "        return data_in.year - born.year\n",
    "\n",
    "def get_area(x):\n",
    "    y = ''\n",
    "    if x == 0:\n",
    "        y = '市区'\n",
    "    elif (x == 1) | (x == 2):\n",
    "        y = '偏远区县'\n",
    "    elif (x == 3) | (x == 4) | (x == 5):\n",
    "        y = '村、乡'\n",
    "    elif x == 8:\n",
    "        y = '县级市'\n",
    "    return y\n",
    "\n",
    "\n",
    "def get_city_area(x):\n",
    "    y = ''\n",
    "    if (re.search(r'县', x) != None):\n",
    "        y = '县'\n",
    "    elif (re.search(r'市|区',x) != None):\n",
    "        y = '市'\n",
    "    return y\n",
    "\n",
    "\n",
    "def city_match(x1, x2):\n",
    "    return True if (re.search(x1, x2) != None) else False\n",
    "\n",
    "\n",
    "def handle_inf(x):\n",
    "    return 0 if math.isinf(x) else x\n",
    "\n",
    "\n",
    "## 给每个值重新编码为分段标签——对应ChiMerge_MaxInterval方法\n",
    "def get_point_dur(x, point):\n",
    "    z = ''\n",
    "    if point:\n",
    "        num_point = len(point) + 1\n",
    "        if (x != -99):\n",
    "            if x <= point[0]:\n",
    "                z = '0- ~' + str(point[0])\n",
    "            elif x > point[-1]:\n",
    "                z = '{}- '.format(num_point-1) + str(point[-1]) + '~'\n",
    "            else:\n",
    "                for i in range(0, num_point-1):\n",
    "                    if point[i] < x <= point[i+1]:\n",
    "                        z = '{}- '.format(i+1) + str(point[i]) + '~' + str(point[i + 1])\n",
    "        else:\n",
    "            z = '-99'\n",
    "    return z\n",
    "\n",
    "\n",
    "def get_max(x, y):\n",
    "    return x if x >= y else y\n",
    "\n",
    "# 随机将样本切分为n等份\n",
    "def split_random(df, n):\n",
    "    df = df.sample(frac=1)\n",
    "    point = int(int(1/n * df.shape[0]))\n",
    "    cut_index = range(point, df.shape[0], point)\n",
    "    dfc1 = df[0: cut_index[0]]\n",
    "    dfc = [df[cut_index[cut_index.index(i)-1]: i] for i in cut_index]\n",
    "    dfc.append(dfc1)\n",
    "    return dfc\n",
    "\n",
    "# 设定训练集\n",
    "\n",
    "def set_train_test(df, n, test_num):\n",
    "    df_test = df[test_num]\n",
    "    n_list = list(range(0, n))\n",
    "    n_list.remove(test_num)\n",
    "    print(n_list)\n",
    "    df_train = pd.concat(df[i]for i in n_list)\n",
    "    df_train['train_test'] = 1\n",
    "    df_test['train_test'] = 0\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    return df\n",
    "\n",
    "def cal_woe(df, classification, col_count, feature_list, other_var):\n",
    "    save_path = r'd:/data/model/贡献值结果-{}.xlsx'.format(str(datetime.today())[0:13])\n",
    "    writer = pd.ExcelWriter(save_path)\n",
    "    df_IV = pd.DataFrame(columns=['英文', 'IV值'])\n",
    "    index = 0\n",
    "    offset = 0\n",
    "    df_train = df[df.train_test == 1]\n",
    "    for i in feature_list:\n",
    "        print(i)\n",
    "        pt = pd.pivot_table(df_train, index=classification, columns=i, values=col_count, aggfunc='count').T\n",
    "        print(pt)\n",
    "        pt['WOEi'] = np.log((pt['good']/pt['good'].sum())/(pt['bad']/pt['bad'].sum())).round(4)\n",
    "        pt['IVi'] = pt.WOEi.mul((pt.good/pt.good.sum())-(pt.bad/pt.bad.sum())).round(3)\n",
    "        pt = pt.fillna(0)\n",
    "        pt.to_excel(writer, 'woe明细', startrow=offset)\n",
    "        key = pt.index.tolist()\n",
    "        value = pt.WOEi.tolist()\n",
    "        dict_v = dict(zip(key, value))\n",
    "        print(dict_v)\n",
    "        df[i] = df[i].map(dict_v)   # 将woe值注入测试集\n",
    "        iv = pt.IVi.sum()\n",
    "        df_IV.at[index, '英文'] = i\n",
    "        df_IV.at[index, 'IV值'] = iv\n",
    "        index += 1\n",
    "        offset += (pt.shape[0] + 2)\n",
    "    pd.merge(df_IV, df_list, on='英文', how='left').to_excel(writer, sheet_name='IV汇总')\n",
    "    woe_value = df[other_var + feature_list].copy()\n",
    "    woe_value.to_excel(writer, sheet_name='woe', index=False)\n",
    "    writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def re_trans(df, ChiMerge_list, target, onkey, save_path):\n",
    "\n",
    "    df_chis = df.loc[:, ['loan_id', 'user_mark', 'classification']]\n",
    " \n",
    "    for var_li in lisan_list:\n",
    "        df_li = df.loc[:, ['loan_id', var_li]]\n",
    "        df_chis = pd.merge(df_chis, df_li, how='left', on='loan_id')\n",
    "    for col in ChiMerge_list:\n",
    "        print(col)\n",
    "        df[col] = df[col].replace('-', None).astype(float)\n",
    "        df_chi = df.loc[:, [onkey, col, target]]\n",
    "        df_chi = df_chi.fillna(-99)\n",
    "        with open(r'd:/code/risk/model_my/split_code_fix.json') as j_file:\n",
    "            j = json.load(j_file)\n",
    "        for i in j:\n",
    "            if i['col_name'] == col:\n",
    "                split_box = i['split_box']\n",
    "                if split_box:\n",
    "                    df_chi[col] = df_chi[col].apply(lambda x: get_point_dur(x, split_box))\n",
    "            df_chi = df_chi.loc[:, [onkey, col]]\n",
    "\n",
    "        df_chis = pd.merge(df_chis, df_chi, how='left', on=onkey)\n",
    "        pd.DataFrame.to_csv(df_chis, save_path, sep=',', encoding=\"utf_8_sig\")\n",
    "        print(datetime.now())\n",
    "\n",
    "    return df_chis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26731 entries, 0 to 26730\n",
      "Columns: 321 entries, card_account to loan_moneymonthly_next12m\n",
      "dtypes: float64(52), int64(265), object(4)\n",
      "memory usage: 65.7+ MB\n",
      "None\n",
      "['card_account', 'card_notsettled', 'card_overdue', 'card_90overdue', 'card_guaranty', 'housing_loan_account', 'housing_loan_notsettled', 'housing_loan_overdue', 'housing_loan_90overdue', 'housing_loan_guaranty', 'other_loan_account', 'other_loan_notsettled', 'other_loan_overdue', 'other_loan_90overdue', 'other_loan_guaranty', 'card_count_only_rmb', 'card_count_card_notsettled', 'card_credit_history', 'card_credit_history_normal', 'card_award_first', 'card_award_first_normal', 'card_award_new', 'card_award_highest', 'card_award_highest_goodbank', 'card_award_used_highest', 'card_award_ratio_highest', 'card_award_sum', 'card_award_used', 'card_award_used_ratio', 'card_exceeding_count_', 'card_exceeding_count_ratio', 'card_exceeding_money_sum', 'card_exceeding_money_max', 'card_overdue_count', 'card_overdue_money_sum', 'card_overdue_money_max', 'card_overdue_months_in_5y', 'card_overdue_months_in_2y', 'card_overdue_months_in_1y', 'card_overdue_over90_in_5y', 'card_overdue_over90_in_2y', 'card_overdue_over90_in_1y', 'card_overdue_highest', 'card_overdue_ratio', 'card_overdue_10', 'card_overdue_20', 'card_overdue_30', 'card_overdue_10_extend_1y', 'card_overdue_20_extend_1y', 'card_overdue_30_extend_1y', 'card_overdue_10_extend_2y', 'card_overdue_20_extend_2y', 'card_overdue_30_extend_2y', 'card_unactivated', 'loan_total_account', 'loan_notsettled_account', 'loan_settle_account', 'loan_settle_past6m', 'loan_settle_past3m', 'loan_settle_past1m', 'loan_settle_past6m_ratio', 'loan_settle_past3m_ratio', 'loan_settle_past1m_ratio', 'loan_settle_next1m', 'loan_settle_next3m', 'loan_settle_next6m', 'loan_settle_next12m', 'loan_award_past6m', 'loan_award_past3m', 'loan_award_past1m', 'loan_award_next1m', 'loan_award_next3m', 'loan_award_next6m', 'loan_award_next12m', 'loan_count_bank', 'loan_ratio_bank', 'loan_count_bank_country_stock', 'loan_ratio_bank_country_stock', 'loan_count_bank_commerce', 'loan_ratio_bank_commerce', 'loan_count_bank_village', 'loan_ratio_bank_village', 'loan_count_bank_rcu_commerce', 'loan_ratio_bank_rcu_commerce', 'loan_count_bank_foreign', 'loan_ratio_bank_foreign', 'loan_count_mcc', 'loan_ratio_mcc', 'loan_count_cfc', 'loan_ratio_cfc', 'loan_count_trust', 'loan_ratio_trust', 'loan_count_afc', 'loan_ratio_afc', 'loan_count_weixin', 'loan_count_mayi', 'loan_history_weixin', 'loan_award_weixin_last', 'loan_history_mayi', 'loan_award_mayi_last', 'loan_count_check', 'loan_count_house', 'loan_award_house', 'loan_award_house_avg', 'loan_count_afl', 'loan_award_afl', 'loan_award_afl_avg', 'loan_count_consume', 'loan_award_consume', 'loan_award_consume_avg', 'loan_count_operate', 'loan_award_operate', 'loan_award_operate_avg', 'loan_count_peasant', 'loan_award_peasant', 'loan_award_peasant_avg', 'loan_count_car', 'loan_award_car', 'loan_award_car_avg', 'loan_overdue_month_5y', 'loan_overdue_month_2y', 'loan_overdue_month_1y', 'loan_90overdue_5y', 'loan_90overdue_2y', 'loan_90overdue_1y', 'loan_house_overdue_month_5y', 'loan_house_overdue_month_2y', 'loan_house_overdue_month_1y', 'loan_house_90overdue_5y', 'loan_house_90overdue_2y', 'loan_house_90overdue_1y', 'loan_overdue_highest', 'loan_overdue_house', 'loan_overdue_ratio_10', 'loan_overdue_ratio_20', 'loan_overdue_ratio_30', 'loan_overdue_10_extend_1y', 'loan_overdue_20_extend_1y', 'loan_overdue_30_extend_1y', 'loan_overdue_10_extend_2y', 'loan_overdue_20_extend_2y', 'loan_overdue_30_extend_2y', 'loan_count_normal', 'loan_count_settle', 'loan_count_overdue', 'loan_count_out', 'loan_house_repaymonth', 'loan_count_normal_in_1y', 'loan_count_settle_in_1y', 'loan_count_overdue_in_1y', 'loan_count_out_in_1y', 'loan_house_moneymonthly', 'loan_other_moneymonthly', 'loan_moneymonthly', 'loan_moneymonthly_notmortgage', 'loan_award_total', 'loan_balance', 'loan_overdue_account', 'loan_award_overdue', 'loan_overdue_money', 'loan_money_1', 'loan_money_1_2', 'loan_money_2_10', 'loan_money_10_20', 'loan_money_20_50', 'loan_money_50_100', 'loan_money_100_200', 'loan_money_200', 'loan_money_over_20', 'loan_money_over_50', 'credit_1m', 'credit_2m', 'credit_3m', 'credit_6m', 'credit_12m', 'credit_org_1m', 'credit_org_2m', 'credit_org_3m', 'credit_org_6m', 'credit_org_12m', 'credit_pers_1m', 'credit_pers_2m', 'credit_pers_3m', 'credit_pers_6m', 'credit_pers_12m', 'credit_org_1m_notplm', 'credit_org_2m_notplm', 'credit_org_3m_notplm', 'credit_org_6m_notplm', 'credit_org_12m_notplm', 'credit_card_1m', 'credit_loan_1m', 'credit_plm_1m', 'credit_qualified_1m', 'credit_presafe_1m', 'credit_pgmgmt_1m', 'credit_guarantee_1m', 'credit_loan_bank_1m', 'credit_loan_mcc_1m', 'credit_loan_cfc_1m', 'credit_loan_fing_1m', 'credit_loan_trust_1m', 'credit_loan_other_1m', 'credit_loan_bank_3m', 'credit_loan_mcc_3m', 'credit_loan_cfc_3m', 'credit_loan_fing_3m', 'credit_loan_trust_3m', 'credit_loan_other_3m', 'loan_refuse_3m', 'loan_refuse_bank_3m', 'loan_refuse_mcc_3m', 'loan_refuse_cfc_3m', 'loan_refuse_fing_3m', 'loan_refuse_trust_3m', 'loan_refuse_other_3m', 'credit_card_2m', 'credit_loan_2m', 'credit_plm_2m', 'credit_approve_2m', 'credit_presafe_2m', 'credit_pgmgmt_2m', 'credit_guarantee_2m', 'credit_card_3m', 'credit_loan_3m', 'credit_plm_3m', 'credit_approve_3m', 'credit_presafe_3m', 'credit_pgmgmt_3m', 'credit_guarantee_3m', 'credit_card_6m', 'credit_loan_6m', 'credit_plm_6m', 'credit_approve_6m', 'credit_presafe_6m', 'credit_pgmgmt_6m', 'credit_guarantee_6m', 'credit_card_12m', 'credit_loan_12m', 'credit_plm_12m', 'credit_approve_12m', 'credit_presafe_12m', 'credit_pgmgmt_12m', 'credit_guarantee_12m', 'credit_bank_village_1m', 'credit_bank_rcu_commerce_1m', 'credit_bank_mcc_1m', 'credit_bank_cfc_1m', 'credit_bank_trust_1m', 'credit_bank_insurer_1m', 'credit_bank_afc_1m', 'credit_bank_check_1m', 'credit_bank_rcu_commerce_2m', 'credit_bank_mcc_2m', 'credit_bank_cfc_2m', 'credit_bank_trust_2m', 'credit_bank_insurer_2m', 'credit_bank_afc_2m', 'credit_bank_check_2m', 'credit_bank_village_3m', 'credit_bank_rcu_commerce_3m', 'credit_bank_mcc_3m', 'credit_bank_cfc_3m', 'credit_bank_trust_3m', 'credit_bank_insurer_3m', 'credit_bank_afc_3m', 'credit_bank_check_3m', 'credit_bank_village_6m', 'credit_bank_rcu_commerce_6m', 'credit_bank_mcc_6m', 'credit_bank_cfc_6m', 'credit_bank_trust_6m', 'credit_bank_insurer_6m', 'credit_bank_afc_6m', 'credit_bank_check_6m', 'credit_bank_village_12m', 'credit_bank_rcu_commerce_12m', 'credit_bank_mcc_12m', 'credit_bank_cfc_12m', 'credit_bank_trust_12m', 'credit_bank_insurer_12m', 'credit_bank_afc_12m', 'credit_bank_check_12m', 'credit_self_1m', 'credit_internet_1m', 'credit_self_2m', 'credit_internet_2m', 'credit_self_3m', 'credit_internet_3m', 'credit_self_6m', 'credit_internet_6m', 'credit_self_12m', 'credit_internet_12m', 'age']\n"
     ]
    }
   ],
   "source": [
    "df_list = pd.read_excel(r'd:/data/model/model_dict.xlsx')\n",
    "df = pd.read_excel(r'd:/data/model/use_data.xlsx')\n",
    "print(df.info())\n",
    "lisan_list = ['sex']\n",
    "list_var = list(df_list[(df_list.使用==1)&(df_list.属性==\"num\")]['英文'])\n",
    "print(list_var)\n",
    "df = df[(df.classification == 'good')|(df.classification == 'bad')]\n",
    "df['user_mark'] = df['classification'].map(lambda x: 1 if x==\"good\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why\n",
      "     loan_id  user_mark classification\n",
      "0        NaN          1           good\n",
      "1        NaN          1           good\n",
      "2        NaN          0            bad\n",
      "3        NaN          1           good\n",
      "4        NaN          0            bad\n",
      "5        NaN          1           good\n",
      "6        NaN          1           good\n",
      "7        NaN          0            bad\n",
      "8        NaN          0            bad\n",
      "9        NaN          1           good\n",
      "10       NaN          1           good\n",
      "11       NaN          0            bad\n",
      "12       NaN          1           good\n",
      "13       NaN          0            bad\n",
      "14       NaN          0            bad\n",
      "15       NaN          1           good\n",
      "16       NaN          1           good\n",
      "17       NaN          1           good\n",
      "18       NaN          1           good\n",
      "19       NaN          1           good\n",
      "20       NaN          1           good\n",
      "21       NaN          1           good\n",
      "22       NaN          1           good\n",
      "23       NaN          1           good\n",
      "24       NaN          1           good\n",
      "25       NaN          0            bad\n",
      "26       NaN          0            bad\n",
      "27       NaN          0            bad\n",
      "28       NaN          1           good\n",
      "29       NaN          1           good\n",
      "..       ...        ...            ...\n",
      "71       NaN          1           good\n",
      "72       NaN          1           good\n",
      "73       NaN          1           good\n",
      "74       NaN          1           good\n",
      "75       NaN          1           good\n",
      "76       NaN          1           good\n",
      "77       NaN          1           good\n",
      "78       NaN          1           good\n",
      "79       NaN          1           good\n",
      "80       NaN          1           good\n",
      "81       NaN          0            bad\n",
      "82       NaN          0            bad\n",
      "83       NaN          1           good\n",
      "84       NaN          1           good\n",
      "85       NaN          1           good\n",
      "86       NaN          0            bad\n",
      "87       NaN          1           good\n",
      "88       NaN          1           good\n",
      "89       NaN          1           good\n",
      "90       NaN          0            bad\n",
      "91       NaN          1           good\n",
      "92       NaN          1           good\n",
      "93       NaN          1           good\n",
      "94       NaN          0            bad\n",
      "95       NaN          0            bad\n",
      "96       NaN          1           good\n",
      "97       NaN          0            bad\n",
      "98       NaN          1           good\n",
      "99       NaN          1           good\n",
      "100      NaN          0            bad\n",
      "\n",
      "[101 rows x 3 columns]\n",
      "card_account\n",
      "2019-06-15 15:42:03.650594\n",
      "card_notsettled\n",
      "2019-06-15 15:42:12.489678\n",
      "card_overdue\n",
      "2019-06-15 15:42:21.620479\n",
      "card_90overdue\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9f1b50c21fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre_trans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'user_mark'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loan_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'd:/data/model/data_614.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-3872b0eff5d0>\u001b[0m in \u001b[0;36mre_trans\u001b[0;34m(df, ChiMerge_list, target, onkey, save_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mdf_chi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_chi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0monkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdf_chis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_chis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_chi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0monkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_chis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf_8_sig\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\p1\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                          copy=copy, indicator=indicator)\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_merge_doc\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m'\\nleft : DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\p1\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             concat_axis=0, copy=self.copy)\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\p1\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   4823\u001b[0m     blocks = [make_block(\n\u001b[1;32m   4824\u001b[0m         \u001b[0mconcatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4825\u001b[0;31m         placement=placement) for placement, join_units in concat_plan]\n\u001b[0m\u001b[1;32m   4826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4827\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\p1\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4823\u001b[0m     blocks = [make_block(\n\u001b[1;32m   4824\u001b[0m         \u001b[0mconcatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4825\u001b[0;31m         placement=placement) for placement, join_units in concat_plan]\n\u001b[0m\u001b[1;32m   4826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4827\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\p1\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m   4916\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Concatenating join units along axis0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4918\u001b[0;31m     \u001b[0mempty_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupcasted_na\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_empty_dtype_and_na\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4920\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n",
      "\u001b[0;32mC:\\p1\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget_empty_dtype_and_na\u001b[0;34m(join_units)\u001b[0m\n\u001b[1;32m   4877\u001b[0m         \u001b[1;31m# are only null blocks, when same upcasting rules must be applied to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4878\u001b[0m         \u001b[1;31m# null upcast classes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4879\u001b[0;31m         \u001b[1;32mif\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_null\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4880\u001b[0m             \u001b[0mnull_upcast_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mupcast_cls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4881\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\properties.pyx\u001b[0m in \u001b[0;36mpandas.lib.cache_readonly.__get__ (pandas\\lib.c:45588)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\p1\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mis_null\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5163\u001b[0m         \u001b[0mchunk_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_len\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   5164\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5165\u001b[0;31m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues_flat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5166\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   5167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\p1\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "re_trans(df, list_var, 'user_mark', 'loan_id', save_path=r'd:/data/model/data_614.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
